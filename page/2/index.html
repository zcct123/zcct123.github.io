<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>ZCCT</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="ZCCT"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="ZCCT"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="ZCCT"><meta property="og:url" content="https://zcct123.github.io/"><meta property="og:site_name" content="ZCCT"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://zcct123.github.io/img/og_image.png"><meta property="article:author" content="zcct"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://zcct123.github.io/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://zcct123.github.io"},"headline":"ZCCT","image":["https://zcct123.github.io/img/og_image.png"],"author":{"@type":"Person","name":"zcct"},"publisher":{"@type":"Organization","name":"ZCCT","logo":{"@type":"ImageObject","url":"https://zcct123.github.io/img/logo.svg"}},"description":""}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link data-pjax rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link data-pjax rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="ZCCT" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">档案</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://gitee.com/zclvct"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2024-09-01T04:00:00.000Z" title="2024/9/1 12:00:00">2024-09-01</time>发表</span><span class="level-item"><time dateTime="2025-05-16T03:15:10.126Z" title="2025/5/16 11:15:10">2025-05-16</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/redis/">redis</a></span><span class="level-item">10 分钟读完 (大约1499个字)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/09/01/redis/redis%20%E9%AB%98%E5%8F%AF%E7%94%A8/">redis 高可用</a></p><div class="content"><h2 id="Sentinel-哨兵"><a href="#Sentinel-哨兵" class="headerlink" title="Sentinel(哨兵)"></a>Sentinel(哨兵)</h2><p>Redis Sentinel是社区版本推出的原生高可用解决方案，其部署架构主要包括两部分：Redis Sentinel集群和Redis数据集群。</p>
<p>其中Redis Sentinel集群是由若干Sentinel节点组成的分布式集群，可以实现故障发现、故障自动转移、配置中心和客户端通知。Redis Sentinel的节点数量要满足2n+1（n&gt;&#x3D;1）的奇数个。</p>
<p><img src="/media/17344063619408/17344118367052.jpg"></p>
<h3 id="优点："><a href="#优点：" class="headerlink" title="优点："></a>优点：</h3><ul>
<li>Redis Sentinel集群部署简单；</li>
<li>能够解决Redis主从模式下的高可用切换问题；</li>
<li>很方便实现Redis数据节点的线形扩展，轻松突破Redis自身单线程瓶颈，可极大满足Redis大容量或高性能的业务需求；</li>
<li>可以实现一套Sentinel监控一组Redis数据节点或多组数据节点。</li>
</ul>
<h3 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a>缺点：</h3><ul>
<li>部署相对Redis主从模式要复杂一些，原理理解更繁琐；</li>
<li>资源浪费，Redis数据节点中slave节点作为备份节点不提供服务；</li>
<li>Redis Sentinel主要是针对Redis数据节点中的主节点的高可用切换，对Redis的数据节点做失败判定分为主观下线和客观下线两种，对于Redis的从节点有对节点做主观下线操作，并不执行故障转移。</li>
<li>不能解决读写分离问题，实现起来相对复杂。</li>
</ul>
<h3 id="建议："><a href="#建议：" class="headerlink" title="建议："></a>建议：</h3><ul>
<li><p>如果监控同一业务，可以选择一套Sentinel集群监控多组Redis数据节点的方案，反之选择一套Sentinel监控一组Redis数据节点的方案。</p>
</li>
<li><p>sentinel monitor <master-name> <ip> <port> <quorum> 配置中的<quorum>建议设置成Sentinel节点的一半加1，当Sentinel部署在多个IDC的时候，单个IDC部署的Sentinel数量不建议超过（Sentinel数量 – quorum）。</p>
</li>
<li><p>合理设置参数，防止误切，控制切换灵敏度控制：<br>  a. quorum</p>
<p>  b. down-after-milliseconds 30000</p>
<p>  c. failover-timeout 180000</p>
<p>  d. maxclient</p>
<p>  e. timeout</p>
</li>
<li><p>部署的各个节点服务器时间尽量要同步，否则日志的时序性会混乱。</p>
</li>
<li><p>Redis建议使用pipeline和multi-keys操作，减少RTT次数，提高请求效率。</p>
</li>
<li><p>自行搞定配置中心（zookeeper），方便客户端对实例的链接访问。</p>
</li>
</ul>
<h2 id="Redis-Cluster"><a href="#Redis-Cluster" class="headerlink" title="Redis Cluster"></a>Redis Cluster</h2><p>Redis Cluster是社区版推出的Redis分布式集群解决方案，主要解决Redis分布式方面的需求，比如，当遇到单机内存，并发和流量等瓶颈的时候，Redis Cluster能起到很好的负载均衡的目的。</p>
<p>Redis Cluster集群节点最小配置6个节点以上（3主3从），其中主节点提供读写操作，从节点作为备用节点，不提供请求，只作为故障转移使用。</p>
<p>Redis Cluster采用虚拟槽分区，所有的键根据哈希函数映射到0～16383个整数槽内，每个节点负责维护一部分槽以及槽所印映射的键值数据。</p>
<p><img src="/media/17344063619408/17344120471921.jpg"></p>
<h3 id="优点：-1"><a href="#优点：-1" class="headerlink" title="优点："></a>优点：</h3><ul>
<li>无中心架构；</li>
<li>数据按照slot存储分布在多个节点，节点间数据共享，可动态调整数据分布；</li>
<li>可扩展性：可线性扩展到1000多个节点，节点可动态添加或删除；</li>
<li>高可用性：部分节点不可用时，集群仍可用。通过增加Slave做standby数据副本，能够实现故障自动failover，节点之间通过gossip协议交换状态信息，用投票机制完成Slave到Master的角色提升；</li>
<li>降低运维成本，提高系统的扩展性和可用性。</li>
</ul>
<h3 id="缺点：-1"><a href="#缺点：-1" class="headerlink" title="缺点："></a>缺点：</h3><ul>
<li>Client实现复杂，驱动要求实现Smart Client，缓存slots mapping信息并及时更新，提高了开发难度，客户端的不成熟影响业务的稳定性。目前仅JedisCluster相对成熟，异常处理部分还不完善，比如常见的“max redirect exception”。</li>
<li>节点会因为某些原因发生阻塞（阻塞时间大于clutser-node-timeout），被判断下线，这种failover是没有必要的。</li>
<li>数据通过异步复制，不保证数据的强一致性。</li>
<li>多个业务使用同一套集群时，无法根据统计区分冷热数据，资源隔离性较差，容易出现相互影响的情况。</li>
<li>Slave在集群中充当“冷备”，不能缓解读压力，当然可以通过SDK的合理设计来提高Slave资源的利用率。</li>
<li>Key批量操作限制，如使用mset、mget目前只支持具有相同slot值的Key执行批量操作。对于映射为不同slot值的Key由于Keys不支持跨slot查询，所以执行mset、mget、sunion等操作支持不友好。</li>
<li>Key事务操作支持有限，只支持多key在同一节点上的事务操作，当多个Key分布于不同的节点上时无法使用事务功能。</li>
<li>Key作为数据分区的最小粒度，不能将一个很大的键值对象如hash、list等映射到不同的节点。</li>
<li>不支持多数据库空间，单机下的redis可以支持到16个数据库，集群模式下只能使用1个数据库空间，即db 0。</li>
<li>复制结构只支持一层，从节点只能复制主节点，不支持嵌套树状复制结构。</li>
<li>避免产生hot-key，导致主库节点成为系统的短板。</li>
<li>避免产生big-key，导致网卡撑爆、慢查询等。</li>
<li>重试时间应该大于cluster-node-time时间。</li>
<li>Redis Cluster不建议使用pipeline和multi-keys操作，减少max redirect产生的场景。</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2024-09-01T04:00:00.000Z" title="2024/9/1 12:00:00">2024-09-01</time>发表</span><span class="level-item"><time dateTime="2025-05-16T03:14:45.812Z" title="2025/5/16 11:14:45">2025-05-16</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/redis/">redis</a></span><span class="level-item">4 分钟读完 (大约540个字)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/09/01/redis/%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5/">主从同步</a></p><div class="content"><p>[TOC]</p>
<p><img src="/media/17344045264751/17344048072495.jpg"></p>
<p><img src="/media/17344045264751/17344062580743.jpg"></p>
<h2 id="全量同步"><a href="#全量同步" class="headerlink" title="全量同步"></a>全量同步</h2><p>主从第一次连接时会执行全量同步，将master节点所有的数据拷贝给slave节点</p>
<p><img src="/media/17344045264751/17344051181197.jpg"></p>
<p>主从节点复制偏移量</p>
<ol>
<li>参与复制的主从节点都会维护自身的复制偏移量。</li>
<li>主节点在处理完写入命令后，会把命令的字节长度做累加记录，统计信息在info replication中的master_repl_offset指标中。</li>
<li>从节点每秒钟上报自身的的复制偏移量（slave_repl_offset）给主节点，主节点会保存从节点的复制偏移量。</li>
<li>从节点在接收到主节点发送的命令后，会累加自身的偏移量，统计信息在info replication中的slave_repl_offset指标中。</li>
<li>通过对比主从节点的复制偏移量，可以判断主从节点数据是否一致。</li>
</ol>
<h2 id="增量同步"><a href="#增量同步" class="headerlink" title="增量同步"></a>增量同步</h2><p><img src="/media/17344045264751/17344051651430.jpg"></p>
<p>Redis 同步的是指令流，主节点会将那些对自己的状态产生修改性影响的指令记录在本 地的内存 buffer 中，然后异步将 buffer 中的指令同步到从节点，从节点一边执行同步的指 令流来达到和主节点一样的状态，一遍向主节点反馈自己同步到哪里了 (偏移量)。<br>因为内存的 buffer 是有限的，所以 Redis 主库不能将所有的指令都记录在内存 buffer 中。Redis 的复制内存 buffer 是一个定长的环形数组，如果数组内容满了，就会从头开始覆盖前面的内容。</p>
<p><img src="/media/17344045264751/17344048578501.jpg"><br>如果因为网络状况不好，从节点在短时间内无法和主节点进行同步，那么当网络状况恢 复时，Redis 的主节点中那些没有同步的指令在 buffer 中有可能已经被后续的指令覆盖掉 了，从节点将无法直接通过指令流来进行同步，这个时候就需要用到更加复杂的同步机制 — — 快照同步。</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2024-09-01T04:00:00.000Z" title="2024/9/1 12:00:00">2024-09-01</time>发表</span><span class="level-item"><time dateTime="2025-05-16T03:14:41.328Z" title="2025/5/16 11:14:41">2025-05-16</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/redis/">redis</a></span><span class="level-item">3 分钟读完 (大约433个字)</span></div></div><div class="content"><ol>
<li>String（字符串）<ul>
<li>特点：最简单的数据结构，可以存储字符串、整数或浮点数。支持原子操作，如递增、递减等。</li>
<li>应用场景：<ul>
<li>存储简单的键值对，如缓存数据、计数器等。</li>
<li>实现分布式锁。</li>
<li>计数器，如网站的访问次数统计。</li>
</ul>
</li>
</ul>
</li>
<li>List（列表）<ul>
<li>特点：有序的字符串列表，支持从两端进行插入和删除操作。</li>
<li>应用场景：<ul>
<li>消息队列，如生产者-消费者模型。</li>
<li>最近浏览记录，如用户最近查看的商品列表。</li>
<li>聊天应用的消息存储。</li>
</ul>
</li>
</ul>
</li>
<li>Set（集合）<ul>
<li>特点：无序的、不重复的字符串集合，支持交集、并集、差集等操作。</li>
<li>应用场景：<ul>
<li>去重，如统计某段时间内的唯一访客。</li>
<li>社交网络的好友关系管理。</li>
<li>标签系统，如文章的标签管理。</li>
</ul>
</li>
</ul>
</li>
<li>Hash（哈希）<ul>
<li>特点：键值对的集合，适合存储对象。</li>
<li>应用场景：<ul>
<li>存储对象属性，如用户信息（用户名、密码、邮箱等）。</li>
<li>会话管理，如存储用户的会话信息。</li>
<li>商品详情，如商品的价格、库存、描述等。</li>
</ul>
</li>
</ul>
</li>
<li>ZSet（有序集合）<ul>
<li>特点：每个成员都有一个分数，集合中的成员按照分数排序，支持范围查询。</li>
<li>应用场景：<ul>
<li>排行榜，如游戏得分排行榜。</li>
<li>时间轴，如微博的时间线。</li>
<li>优先级队列，如任务调度系统。</li>
</ul>
</li>
</ul>
</li>
</ol>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2024-09-01T04:00:00.000Z" title="2024/9/1 12:00:00">2024-09-01</time>发表</span><span class="level-item"><time dateTime="2025-05-16T03:15:32.374Z" title="2025/5/16 11:15:32">2025-05-16</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/redis/">redis</a></span><span class="level-item">7 分钟读完 (大约981个字)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/09/01/redis/ziplist%20(%E5%8E%8B%E7%BC%A9%E5%88%97%E8%A1%A8)/">ziplist (压缩列表)</a></p><div class="content"><p>[TOC]</p>
<p>ziplist 是一个经过特殊编码的双向链表，旨在提高内存效率。 它存储字符串和整数值，其中整数被编码为实际整数而不是一系列字符。 它允许在 O(1) 时间内在列表的任一侧进行推送和弹出操作。 但是，由于每个操作都需要重新分配 ziplist 使用的内存，因此实际复杂性与 ziplist 使用的内存量有关。</p>
<ul>
<li>ziplist 为了节省内存，采用了紧凑的连续存储。所以在修改操作下并不能像一般的链表那么容易，需要从新分配新的内存，然后复制到新的空间。</li>
<li>ziplist 是一个双向链表，可以在时间复杂度为 O(1) 从下头部、尾部进行 pop 或 push。</li>
<li>新增或更新元素可能会出现连锁更新现象。</li>
<li>不能保存过多的元素，否则查询效率就会降低。</li>
</ul>
<h2 id="特殊双向链表"><a href="#特殊双向链表" class="headerlink" title="特殊双向链表"></a>特殊双向链表</h2><p>ziplist 是一个特殊双向链表，不像普通的链表使用前后指针关联在一起，它是存储在连续内存上的.</p>
<p><img src="/media/17344031528589/17344036702469.jpg"></p>
<ul>
<li>zlbytes: 32 位无符号整型，记录 ziplist 整个结构体的占用空间大小。当然了也包括 zlbytes 本身。这个结构有个很大的用处，就是当需要修改 ziplist 时候不需要遍历即可知道其本身的大小。 这个 SDS 中记录字符串的长度有相似之处，这些好的设计往往在平时的开发中可以采纳一下。</li>
<li>zltail: 32 位无符号整型, 记录整个 ziplist 中最后一个 entry 的偏移量。所以在尾部进行 POP 操作时候不需要先遍历一次。</li>
<li>zllen: 16 位无符号整型, 记录 entry 的数量， 所以只能表示 2^16。但是 Redis 作了特殊的处理：当实体数超过 2^16 ,该值被固定为 2^16 - 1。 所以这种时候要知道所有实体的数量就必须要遍历整个结构了。</li>
<li>entry: 真正存数据的结构。</li>
<li>zlend: 8 位无符号整型, 固定为 255 (0xFF)。为 ziplist 的结束标识。</li>
</ul>
<h2 id="entry节点"><a href="#entry节点" class="headerlink" title="entry节点"></a>entry节点</h2><p>每个 entry 都包含两条信息的元数据为前缀：</p>
<ul>
<li>第一元数据用来存储前一个 entry 的长度，以便能够从后向前遍历列表。</li>
<li>第二元数据是表示 entry 的编码形式。 用来表示 entry 类型，整数或字符串，在字符串的情况下，它还表示字符串有效的长度。</li>
</ul>
<p><img src="/media/17344031528589/17344041410534.jpg"><br><strong>prelen</strong></p>
<p>记录前一个 entry 的长度。若前一个 entry 的长度小于 254 , 则使用 1 个字节的 8 位无符号整数来表示。<br>若前一个 entry 长度大于等于 254，则使用 5 个字节来表示。第 1 个字节固定为 254 (FE) 作为标识，剩余 4 字节则用来表示前一个 entry 的实际大小。</p>
<h2 id="连锁更新"><a href="#连锁更新" class="headerlink" title="连锁更新"></a>连锁更新</h2><p>ziplist 在更新或者新增时候，如空间不够则需要对整个列表进行重新分配。当新插入的元素较大时，可能会导致后续元素的 prevlen 占用空间都发生变化，从而引起「连锁更新」问题，导致每个元素的空间都要重新分配，造成访问压缩列表性能的下降。</p>
<p>ziplist 节点的 prevlen 属性会根据前一个节点的长度进行不同的空间大小分配：</p>
<ul>
<li>如果前一个节点的长度小于 254 字节，那么 prevlen 属性需要用 1 字节的空间来保存这个长度值。</li>
<li>如果前一个节点的长度大于等于 254 字节，那么 prevlen 属性需要用 5 字节的空间来保存这个长度值。</li>
</ul>
<p><img src="/media/17344031528589/17344044323954.jpg"></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2024-09-01T04:00:00.000Z" title="2024/9/1 12:00:00">2024-09-01</time>发表</span><span class="level-item"><time dateTime="2025-05-16T03:14:32.476Z" title="2025/5/16 11:14:32">2025-05-16</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/redis/">redis</a></span><span class="level-item">7 分钟读完 (大约985个字)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/09/01/redis/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/">布隆过滤器</a></p><div class="content"><p>[TOC]</p>
<p>布隆过滤器（Bloom Filter）是一种空间效率高的概率数据结构，用于测试一个元素是否属于一个集合。它允许少量的误判（即可能会错误地认为一个元素属于集合，但实际上不属于），但不会出现误判为不属于的情况。布隆过滤器广泛应用于缓存系统、数据库、网络路由等领域。</p>
<ul>
<li>缓存系统：用于快速判断一个元素是否在缓存中。</li>
<li>数据库：用于索引和快速查找。</li>
<li>网络路由：用于快速判断一个 IP 地址是否在黑名单中。</li>
<li>垃圾邮件过滤：用于快速判断一封邮件是否为垃圾邮件</li>
</ul>
<h2 id="Redis-中的布隆过滤器使用"><a href="#Redis-中的布隆过滤器使用" class="headerlink" title="Redis 中的布隆过滤器使用"></a>Redis 中的布隆过滤器使用</h2><p>Redis 官方提供的布隆过滤器到了 Redis 4.0 提供了插件功能之后才正式登场。布隆过滤 器作为一个插件加载到 Redis Server 中，给 Redis 提供了强大的布隆去重功能。</p>
<p>布隆过滤器有二个基本指令，bf.add  添加元素，bf.exists 查询元素是否存在，它的用法 和 set 集合的 sadd 和 sismember 差不多。注意 bf.add  只能一次添加一个元素，如果想要 一次添加多个，就需要用到 bf.madd  指令。同样如果需要一次查询多个元素是否存在，就需 要用到 bf.mexists 指令。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; bf.add codehole user1</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; bf.add codehole user2</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; bf.add codehole user3</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; bf.exists codehole user1</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; bf.exists codehole user2</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; bf.exists codehole user3</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; bf.exists codehole user4</span><br></pre></td></tr></table></figure>

<p>Redis 其实还提供了自定义参数的布隆过滤器，需要我们在 add 之前使用 bf.reserve 指令显式创建。如果对应的 key 已经存在，bf.reserve 会报错。bf.reserve 有三个参数，分别是 key, error_rate 和 initial_size。错误率越低，需要的空间越大。initial_size 参数表示预计放 入的元素数量，当实际数量超出这个数值时，误判率会上升。所以需要提前设置一个较大的数值避免超出导致误判率升高。如果不使用 bf.reserve，默 认的 error_rate 是 0.01，默认的 initial_size 是 100。</p>
<h2 id="布隆过滤器原理"><a href="#布隆过滤器原理" class="headerlink" title="布隆过滤器原理"></a>布隆过滤器原理</h2><p>下图表示向布隆过滤器中添加元素 <a target="_blank" rel="noopener" href="http://www.123.com/">www.123.com</a> 和 <a target="_blank" rel="noopener" href="http://www.456.com/">www.456.com</a> 的过程，它使用了 func1 和 func2 两个简单的哈希函数。</p>
<p><img src="/media/17338823475199/17338860668627.jpg"></p>
<ol>
<li>初始化：当我们创建一个布隆过滤器时，我们首先创建一个全由0组成的位数组（bit array)。同时，我们还需选择几个独立的哈希函数，每个函数都可以将集合中的元素映射到这个位数组的某个位置。</li>
<li>添加元素：在布隆过滤器中添加一个元素时，我们会将此元素通过所有的哈希函数进行映射，得到在位数组中的几个位置，然后将这些位置标记为1。</li>
<li>查询元素：如果我们要检查一个元素是否在集合中，我们同样使用这些哈希函数将元素映射到位数组中的几个位置，如果所有的位置都被标记为1，那么我们就可以说该元素可能在集合中。如果有任何一个位置不为1，那么该元素肯定不在集合中。</li>
</ol>
<p>我们可以提高数组长度以及 hash 计算次数来降低误报率，但是相应的 CPU、内存的消耗也会相应地提高，会增加存储和计算的开销。因此，布隆过滤器的使用需要在误判率和性能之间进行权衡。</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2024-09-01T04:00:00.000Z" title="2024/9/1 12:00:00">2024-09-01</time>发表</span><span class="level-item"><time dateTime="2025-05-16T03:14:38.321Z" title="2025/5/16 11:14:38">2025-05-16</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/redis/">redis</a></span><span class="level-item">5 分钟读完 (大约735个字)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/09/01/redis/%E8%BF%87%E6%9C%9F%E7%AD%96%E7%95%A5%E4%B8%8E%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0/">过期策略与内存淘汰</a></p><div class="content"><p>redis 会将每个设置了过期时间的 key 放入到一个独立的字典中，以后会定时遍历这个 字典来删除到期的 key。</p>
<h1 id="过期策略"><a href="#过期策略" class="headerlink" title="过期策略"></a>过期策略</h1><h2 id="惰性删除"><a href="#惰性删除" class="headerlink" title="惰性删除"></a>惰性删除</h2><p> 惰性策略就是在客户端访问这个 key 的时候，redis 对 key 的过期时间进行检查，如果过期了就立即删除。</p>
<h2 id="定时扫描"><a href="#定时扫描" class="headerlink" title="定时扫描"></a>定时扫描</h2><p>Redis 默认会每秒进行十次过期扫描，过期扫描不会遍历过期字典中所有的 key，而是 采用了一种简单的贪心策略。</p>
<ol>
<li>从过期字典中随机  20  个  key；</li>
<li>删除这  20  个  key  中已经过期的  key；</li>
<li>如果过期的  key  比率超过  1&#x2F;4，那就重复步骤  1；</li>
</ol>
<p>同时，为了保证过期扫描不会出现循环过度，导致线程卡死现象，算法还增加了扫描时 间的上限，默认不会超过 25ms。</p>
<h1 id="内存淘汰"><a href="#内存淘汰" class="headerlink" title="内存淘汰"></a>内存淘汰</h1><p>为了限制最大使用内存，Redis 提供了配置参数 maxmemory 来限制内存超出期望大小。<br>当实际内存超出 maxmemory 时，Redis 提供了几种可选策略 (maxmemory-policy) 来让用户自己决定该如何腾出新的空间以继续提供读写服务。</p>
<ul>
<li>noeviction  不会继续服务写请求 (DEL 请求可以继续服务)，读请求可以继续进行。这样 可以保证不会丢失数据，但是会让线上的业务不能持续进行。这是默认的淘汰策略。</li>
<li>volatile-lru  尝试淘汰设置了过期时间的 key，最少使用的 key 优先被淘汰。没有设置过 期时间的 key 不会被淘汰，这样可以保证需要持久化的数据不会突然丢失。</li>
<li>volatile-ttl 跟上面一样，除了淘汰的策略不是 LRU，而是 key 的剩余寿命 ttl 的值，ttl 越小越优先被淘汰。</li>
<li>volatile-random 跟上面一样，不过淘汰的 key 是过期 key 集合中随机的 key。</li>
<li>allkeys-lru  区别于 volatile-lru，这个策略要淘汰的 key 对象是全体的 key 集合，而不 只是过期的 key 集合。这意味着没有设置过期时间的 key 也会被淘汰。</li>
<li>allkeys-random 跟上面一样，不过淘汰的策略是随机的 key。</li>
<li>volatile-xxx 策略只会针对带过期时间的 key 进行淘汰，allkeys-xxx 策略会对所有的 key 进行淘汰。如果你只是拿 Redis 做缓存，那应该使用 allkeys-xxx，客户端写缓存时 不必携带过期时间。如果你还想同时使用 Redis 的持久化功能，那就使用 volatile-xxx 策略，这样可以保留没有设置过期时间的 key，它们是永久的 key 不会被 LRU 算法淘 汰。</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2024-09-01T04:00:00.000Z" title="2024/9/1 12:00:00">2024-09-01</time>发表</span><span class="level-item"><time dateTime="2025-05-16T03:14:35.409Z" title="2025/5/16 11:14:35">2025-05-16</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/redis/">redis</a></span><span class="level-item">13 分钟读完 (大约1890个字)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/09/01/redis/%E6%8C%81%E4%B9%85%E5%8C%96/">redis持久化</a></p><div class="content"><p>[TOC]</p>
<h2 id="RDB（Redis-Database-Backup）"><a href="#RDB（Redis-Database-Backup）" class="headerlink" title="RDB（Redis Database Backup）"></a>RDB（Redis Database Backup）</h2><p>RDB 是一种快照持久化方式，它会在指定的时间间隔内将内存中的数据集快照写入磁盘。</p>
<h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ul>
<li>生成速度快：RDB文件是一个紧凑的二进制文件，生成速度快，对系统性能影响较小。</li>
<li>恢复速度快：由于RDB文件包含了某一时刻的完整数据集，恢复速度非常快。</li>
</ul>
<h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><ul>
<li>数据丢失风险：如果Redis在两次生成RDB文件之间发生故障，这段时间内的数据将会丢失。</li>
<li>文件体积较大：RDB 文件会占用较多的磁盘空间。</li>
<li>CPU和I&#x2F;O开销：生成RDB文件时，Redis需要进行大量数据的序列化和I&#x2F;O操作，会对CPU和I&#x2F;O资源造成一定的压力。</li>
</ul>
<h4 id="手动方式"><a href="#手动方式" class="headerlink" title="手动方式"></a>手动方式</h4><ul>
<li>save：save 命令会阻塞 Redis 服务器进程，直到 RDB 文件创建完毕为止，在服务器进程阻塞期间，服务器不能处理任何命令请求。</li>
<li>bgsave：bgsave 命令会 fork 一个子进程（注意是子进程，不是子线程）在后台生成快照文件，不会阻塞 Redis 服务器，服务器进程（父进程）可以继续处理命令请求。</li>
</ul>
<p>bgsave命令执行期间，客户端发送的 save 和 bgsave 命令会被拒绝，这样的目的是为了防止父进程和子进程之间产生竞争。</p>
<h4 id="自动方式"><a href="#自动方式" class="headerlink" title="自动方式"></a>自动方式</h4><p>自动方式是指通过服务器配置文件的 save 选项，来让 Redis 每隔一段时间自动执行 bgsave ，本质上还是通过 bgsave 命令去实现。</p>
<p>在 redis.conf 文件中，可以通过以下配置项来启用和调整 RDB 持久化：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 是否开启 RDB 持久化</span><br><span class="line"> save 3600 1          （3600秒后，如果至少发生了1次写入，则存一次）</span><br><span class="line"> save 300 100        （300秒后，如果至少发生了100次写入，则存一次）</span><br><span class="line"> save 60 10000      （60秒后，如果至少发生了10000次写入，则存一次）</span><br><span class="line"></span><br><span class="line"># RDB 文件的名称</span><br><span class="line">dbfilename dump.rdb</span><br><span class="line"></span><br><span class="line"># RDB 文件的保存路径</span><br><span class="line">dir /var/lib/redis</span><br></pre></td></tr></table></figure>

<ul>
<li><p>注意1：二者要必须同时满足，即写入次数和发生时间。</p>
<p>  比如距离上次写入过了59秒，在59秒内累积发生了9999次写入，那么在60秒的时候并不会发生写入操作，因为60秒的时候9999 &lt; 10000，等到了300秒后，因为9999 &gt; 100，条件都满足，所以会在距离上次写入300秒的时候发生一次写入db操作。</p>
</li>
<li><p>注意2：条件由上往下执行，如果上一个条件满足了，则不进行下个条件的判断了，直接存入db</p>
</li>
<li><p>注意3：配置原则是判断时间越长（第一个参数），写入次数越少（第二个参数），如果配置错误，导致频繁的存入db，可能会造成性能问题</p>
</li>
<li><p>注意4：这里是写入操作，并不是说改变次数，比如说 set a a; set a a;执行两次这个操作，算两次写入，虽然值没有变，但是也是会算在写入次数里面的。</p>
</li>
</ul>
<h2 id="AOF（Append-Only-File）"><a href="#AOF（Append-Only-File）" class="headerlink" title="AOF（Append Only File）"></a>AOF（Append Only File）</h2><p>AOF 是一种日志持久化方式，它会记录服务器接收到的每个写操作命令，并在服务器启动时通过重新执行这些命令来恢复数据。</p>
<h4 id="优点-1"><a href="#优点-1" class="headerlink" title="优点"></a>优点</h4><ul>
<li>数据安全性高：AOF文件记录了每个写操作命令，即使Redis发生故障，也可以通过重放AOF文件中的命令来恢复数据，数据安全性高。</li>
<li>可读性好：AOF文件是以文本形式记录的，可以方便地进行查看和编辑。</li>
</ul>
<h4 id="缺点-1"><a href="#缺点-1" class="headerlink" title="缺点"></a>缺点</h4><ul>
<li>文件体积大：AOF文件记录了每个写操作命令，文件体积通常比RDB文件大。</li>
<li>恢复速度慢：由于需要重放AOF文件中的所有命令，恢复速度比RDB慢。</li>
</ul>
<p>当启用 AOF 时，Redis 发生写命令时其实并不是直接写入到AOF 文件，而是将写命令追加到AOF缓冲区的末尾，之后 AOF缓存区再同步至 AOF文件中。</p>
<p><img src="/media/17343266226771/17343307653860.jpg"></p>
<p>AOF 缓存区同步至 AOF 文件，这一过程由名为 flushAppendonlyFile 的函数完成。</p>
<p>而 flushAppendOnlyFile 函数的行为由服务器配置文件的 appendfsync 选项来决定，该参数有以下三个选项：</p>
<ul>
<li>always：每次发生写命令，都同步到 AOF 文件，是最安全的选项。</li>
<li>everysec：每秒钟同步写入一次到 AOF 文件，在性能和安全之间做了一个平衡。</li>
<li>no：不主动写入 AOF 文件，何时同步由操作系统来决定。</li>
</ul>
<p>默认情况下，Redis的 appendfsync 参数为 everysec 。如果需要提高持久化安全性，可以将其改为 always ，如果更关注性能，则可以将其改为 no。但是需要注意的是，使用 no 可能会导致数据丢失的风险，建议在应用场景允许的情况下谨慎使用。</p>
<h4 id="AOF-重写"><a href="#AOF-重写" class="headerlink" title="AOF 重写"></a>AOF 重写</h4><p>Redis的 AOF 重写机制指的是将 AOF 文件中的冗余命令删除，以减小 AOF 文件的大小并提高读写性能的过程。</p>
<p>通过该功能，Redis 服务器可以创建一个新的 AOF 文件来替代现有的 AOF 文件，新旧两个 AOF 文件所保存的数据库状态相同，但新 AOF 文件不会包含任何浪费空间的冗余命令，所以新 AOF 文件的体积通常会比旧 AOF 文件的体积要小得多。</p>
<h2 id="混合持久化"><a href="#混合持久化" class="headerlink" title="混合持久化"></a>混合持久化</h2><p>让用户能够同时拥有上述两种持久化的优点， Redis 4.0 推出了一个“鱼和熊掌兼得”的持久化方案 —— RDB-AOF 混合持久化。</p>
<p>这种持久化能够通过 AOF 重写操作创建出一个同时包含 RDB 数据和 AOF 数据的 AOF 文件， 其中 RDB 数据位于 AOF 文件的开头， 它们储存了服务器开始执行重写操作时的数据库状态。至于那些在重写操作执行之后执行的 Redis 命令， 则会继续以 AOF 格式追加到 AOF 文件的末尾， 也即是 RDB 数据之后。</p>
<p>也就是说当开启混合持久化之后，AOF文件中的内容：前半部分是二进制的RDB内容，后面跟着AOF增加的数据，AOF位于两次RDB之间。</p>
<p>格式会类似下面这样：</p>
<p><img src="/media/17343266226771/17343310335139.jpg"></p>
<p><img src="/media/17343266226771/17343326914589.jpg"></p>
<h4 id="优点-2"><a href="#优点-2" class="headerlink" title="优点"></a>优点</h4><ul>
<li>恢复速度快：RDB 文件恢复速度快，减少了重启时的数据加载时间。</li>
<li>数据完整性：AOF 记录所有写操作，确保数据完整性。</li>
<li>文件大小适中：混合持久化文件比纯 AOF 文件小，但比纯 RDB 文件大。</li>
</ul>
<h4 id="缺点-2"><a href="#缺点-2" class="headerlink" title="缺点"></a>缺点</h4><ul>
<li>复杂性增加：混合持久化增加了 Redis 的复杂性，需要更多的配置和管理。</li>
<li>内存消耗：AOF 重写时会生成临时的 RDB 文件，可能会增加内存消耗。</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2024-09-01T04:00:00.000Z" title="2024/9/1 12:00:00">2024-09-01</time>发表</span><span class="level-item"><time dateTime="2025-05-16T03:11:58.599Z" title="2025/5/16 11:11:58">2025-05-16</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F/">分布式</a></span><span class="level-item">11 分钟读完 (大约1582个字)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/09/01/%E5%88%86%E5%B8%83%E5%BC%8F/%E4%BA%8B%E5%8A%A1%E5%A4%84%E7%90%86/CAP%E7%90%86%E8%AE%BA%20/">CAP理论</a></p><div class="content"><p>[TOC]</p>
<p>CAP 定理（Consistency、Availability、Partition Tolerance Theorem）,这个定理里描述了一个分布式的系统中，涉及共享数据问题时，以下三个特性最多只能同时满足其中两个：</p>
<ul>
<li><p>一致性（Consistency）：代表数据在任何时刻、任何分布式节点中所看到的都是符合预期的。</p>
</li>
<li><p>可用性（Availability）：代表系统不间断地提供服务的能力，理解可用性要先理解与其密切相关两个指标：可靠性（Reliability）和可维护性（Serviceability）。可靠性使用平均无故障时间（Mean Time Between Failure，MTBF）来度量；可维护性使用平均可修复时间（Mean Time To Repair，MTTR）来度量。可用性衡量系统可以正常使用的时间与总时间之比，其表征为：A&#x3D;MTBF&#x2F;（MTBF+MTTR），即可用性是由可靠性和可维护性计算得出的比例值，譬如 99.9999%可用，即代表平均年故障修复时间为 32 秒。</p>
</li>
<li><p>分区容忍性（Partition Tolerance）：代表分布式环境中部分节点因网络原因而彼此失联后，即与其他节点形成“网络分区”时，系统仍能正确地提供服务的能力。</p>
</li>
</ul>
<p>例如一个来自最终用户的交易请求，将交由账号、商家和仓库服务集群中某一个节点来完成响应，每一个单独的服务节点都有自己的数据库：<br><img src="/media/17345791777624/17345948632219.jpg"></p>
<ul>
<li>如果该变动信息没有及时同步给其他账号节点，将导致有可能发生用户购买另一商品时，被分配给到另一个节点处理，由于<strong>看到账号上有不正确的余额而错误地发生了原本无法进行的交易</strong>，此为一致性问题。</li>
<li>如果由于要把该变动信息同步给其他账号节点，<strong>必须暂时停止对该用户的交易服务</strong>，直至数据同步一致后再重新恢复，将可能导致用户在下一次购买商品时，因系统暂时无法提供服务而被拒绝交易，此为可用性问题。</li>
<li>如果由于账号服务集群中某一部分节点，<strong>因出现网络问题，无法正常与另一部分节点交换账号变动信息</strong>，此时服务集群中无论哪一部分节点对外提供的服务都可能是不正确的，整个集群能否承受由于部分节点之间的连接中断而仍然能够正确地提供服务，此为分区容忍性。</li>
</ul>
<p>舍弃 C、A、P 时所带来的不同影响：</p>
<ul>
<li><p>如果放弃分区容忍性（CA without P），意味着我们将假设节点之间通信永远是可靠的。永远可靠的通信在分布式系统中必定不成立的，这不是你想不想的问题，而是只要用到网络来共享数据，分区现象就会始终存在。在现实中，最容易找到放弃分区容忍性的例子便是传统的关系数据库集群，这样的集群虽然依然采用由网络连接的多个节点来协同工作，但数据却不是通过网络来实现共享的。以 Oracle 的 RAC 集群为例，它的每一个节点均有自己独立的 SGA、重做日志、回滚日志等部件，但各个节点是通过共享存储中的同一份数据文件和控制文件来获取数据的，通过共享磁盘的方式来避免出现网络分区。因而 Oracle RAC 虽然也是由多个实例组成的数据库，但它并不能称作是分布式数据库。</p>
</li>
<li><p>如果放弃可用性（CP without A），意味着我们将假设一旦网络发生分区，节点之间的信息同步时间可以无限制地延长，此时，问题相当于退化到前面“全局事务”中讨论的一个系统使用多个数据源的场景之中，我们可以通过 2PC&#x2F;3PC 等手段，同时获得分区容忍性和一致性。在现实中，选择放弃可用性的 CP 系统情况一般用于对数据质量要求很高的场合中，除了 DTP 模型的分布式数据库事务外，著名的 HBase 也是属于 CP 系统，以 HBase 集群为例，假如某个 RegionServer 宕机了，这个 RegionServer 持有的所有键值范围都将离线，直到数据恢复过程完成为止，这个过程要消耗的时间是无法预先估计的。</p>
</li>
<li><p>如果放弃一致性（AP without C），意味着我们将假设一旦发生分区，节点之间所提供的数据可能不一致。选择放弃一致性的 AP 系统目前是设计分布式系统的主流选择，因为 P 是分布式网络的天然属性，你再不想要也无法丢弃；而 A 通常是建设分布式的目的，如果可用性随着节点数量增加反而降低的话，很多分布式系统可能就失去了存在的价值，除非银行、证券这些涉及金钱交易的服务，宁可中断也不能出错，否则多数系统是不能容忍节点越多可用性反而越低的。目前大多数 NoSQL 库和支持分布式的缓存框架都是 AP 系统，以 Redis 集群为例，如果某个 Redis 节点出现网络分区，那仍不妨碍各个节点以自己本地存储的数据对外提供缓存服务，但这时有可能出现请求分配到不同节点时返回给客户端的是不一致的数据。</p>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2024-09-01T04:00:00.000Z" title="2024/9/1 12:00:00">2024-09-01</time>发表</span><span class="level-item"><time dateTime="2025-05-16T03:11:55.018Z" title="2025/5/16 11:11:55">2025-05-16</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F/">分布式</a></span><span class="level-item">2 分钟读完 (大约259个字)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/09/01/%E5%88%86%E5%B8%83%E5%BC%8F/%E4%BA%8B%E5%8A%A1%E5%A4%84%E7%90%86/%E5%85%B1%E4%BA%AB%E4%BA%8B%E5%8A%A1/">共享事务</a></p><div class="content"><p>共享事务（Share Transaction）是指多个服务共用同一个数据源。</p>
<p>为了实现共享事务，就必须新增一个“交易服务器”的中间角色，无论是用户服务、商家服务还是仓库服务，它们都通过同一台交易服务器来与数据库打交道。如果将交易服务器的对外接口按照 JDBC 规范来实现的话，那它完全可以视为是一个独立于各个服务的远程数据库连接池，或者直接作为数据库代理来看待。此时三个服务所发出的交易请求就有可能做到交由交易服务器上的同一个数据库连接，通过本地事务的方式完成。</p>
<p><strong>交易服务器根据不同服务节点传来的同一个事务 ID，使用同一个数据库连接来处理跨越多个服务的交易事务</strong></p>
<p><img src="/media/17345765505995/17345791361767.jpg"></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2024-09-01T04:00:00.000Z" title="2024/9/1 12:00:00">2024-09-01</time>发表</span><span class="level-item"><time dateTime="2025-05-16T03:11:51.448Z" title="2025/5/16 11:11:51">2025-05-16</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F/">分布式</a></span><span class="level-item">33 分钟读完 (大约4907个字)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/09/01/%E5%88%86%E5%B8%83%E5%BC%8F/%E4%BA%8B%E5%8A%A1%E5%A4%84%E7%90%86/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/">分布式事务</a></p><div class="content"><p>[TOC]</p>
<p>分布式事务（Distributed Transaction）特指多个服务同时访问多个数据源的事务处理机制。</p>
<p><strong>分布式事务中没有一揽子包治百病的解决办法，因地制宜地选用合适的事务处理方案才是唯一有效的做法。</strong></p>
<p>我们在 CAP、ACID 中讨论的一致性称为“强一致性”（Strong Consistency），有时也称为“线性一致性”（Linearizability，通常是在讨论共识算法的场景中），而把牺牲了 C 的 AP 系统又要尽可能获得正确的结果的行为被称为“最终一致性”（Eventual Consistency），它是指：如果数据在一段时间之内没有被另外的操作所更改，那它最终将会达到与强一致性过程相同的结果，有时候面向最终一致性的算法也被称为“乐观复制算法”。</p>
<p>把使用 ACID 的事务称为“刚性事务”，下面将要介绍几种分布式事务的常见做法统称为“柔性事务”。</p>
<h2 id="可靠事件队列-（最大努力交付）"><a href="#可靠事件队列-（最大努力交付）" class="headerlink" title="可靠事件队列 （最大努力交付）"></a>可靠事件队列 （最大努力交付）</h2><p><img src="/media/17351963437904/17351973443859.jpg"></p>
<ol>
<li>最终用户向 Fenix’s Bookstore 发送交易请求：购买一本价值 100 元的《深入理解 Java 虚拟机》。</li>
<li>Fenix’s Bookstore 首先应对用户账号扣款、商家账号收款、库存商品出库这三个操作有一个出错概率的先验评估，根据出错概率的大小来安排它们的操作顺序，这种评估一般直接体现在程序代码中，有一些大型系统也可能会实现动态排序。譬如，根据统计，最有可能的出现的交易异常是用户购买了商品，但是不同意扣款，或者账号余额不足；其次是仓库发现商品库存不够，无法发货；风险最低的是收款，如果到了商家收款环节，一般就不会出什么意外了。那顺序就应该安排成最容易出错的最先进行，即：账号扣款 → 仓库出库 → 商家收款。</li>
<li>账号服务进行扣款业务，如扣款成功，则在自己的数据库建立一张消息表，里面存入一条消息：“事务 ID：某 UUID，扣款：100 元（状态：已完成），仓库出库《深入理解 Java 虚拟机》：1 本（状态：进行中），某商家收款：100 元（状态：进行中）”，注意，这个步骤中“扣款业务”和“写入消息”是使用同一个本地事务写入账号服务自己的数据库的。</li>
<li>在系统中建立一个消息服务，定时轮询消息表，将状态是“进行中”的消息同时发送到库存和商家服务节点中去（也可以串行地发，即一个成功后再发送另一个，但在我们讨论的场景中没必要）。这时候可能产生以下几种情况。<ol>
<li>商家和仓库服务都成功完成了收款和出库工作，向用户账号服务器返回执行结果，用户账号服务把消息状态从“进行中”更新为“已完成”。整个事务宣告顺利结束，达到最终一致性的状态。</li>
<li>商家或仓库服务中至少一个因网络原因，未能收到来自用户账号服务的消息。此时，由于用户账号服务器中存储的消息状态一直处于“进行中”，所以消息服务器将在每次轮询的时候持续地向未响应的服务重复发送消息。这个步骤的可重复性决定了所有被消息服务器发送的消息都必须具备幂等性，通常的设计是让消息带上一个唯一的事务 ID，以保证一个事务中的出库、收款动作会且只会被处理一次。</li>
<li>商家或仓库服务有某个或全部无法完成工作，譬如仓库发现《深入理解 Java 虚拟机》没有库存了，此时，仍然是持续自动重发消息，直至操作成功（譬如补充了新库存），或者被人工介入为止。由此可见，<strong>可靠事件队列只要第一步业务完成了，后续就没有失败回滚的概念，只许成功，不许失败。</strong></li>
<li>商家和仓库服务成功完成了收款和出库工作，但回复的应答消息因网络原因丢失，此时，用户账号服务仍会重新发出下一条消息，但因操作具备幂等性，所以不会导致重复出库和收款，只会导致商家、仓库服务器重新发送一条应答消息，此过程重复直至双方网络通信恢复正常。</li>
</ol>
</li>
</ol>
<p>也有一些支持分布式事务的消息框架，如 RocketMQ，原生就支持分布式事务操作，这时候上述情况 2、4 也可以交由消息框架来保障。</p>
<p>可靠事件队列还有一种更普通的形式，被称为“最大努力一次提交”（Best-Effort 1PC），指的就是将最有可能出错的业务以本地事务的方式完成后，采用不断重试的方式（不限于消息系统）来促使同一个分布式事务中的其他关联业务全部完成。</p>
<p>可靠消息队列虽然能保证最终的结果是相对可靠的，过程也足够简单（相对于 TCC 来说），但整个过程完全没有任何隔离性可言，有一些业务中隔离性是无关紧要的，但有一些业务中缺乏隔离性就会带来许多麻烦。譬如在本章的场景事例中，缺乏隔离性会带来的一个显而易见的问题便是“超售”：完全有可能两个客户在短时间内都成功购买了同一件商品，而且他们各自购买的数量都不超过目前的库存，但他们购买的数量之和却超过了库存。</p>
<h2 id="TCC-事务-（Try-Confirm-Cancel）"><a href="#TCC-事务-（Try-Confirm-Cancel）" class="headerlink" title="TCC 事务  （Try-Confirm-Cancel）"></a>TCC 事务  （Try-Confirm-Cancel）</h2><p>TCC 较为烦琐，它是一种业务侵入式较强的事务方案，要求业务处理过程必须拆分为“预留业务资源”和“确认&#x2F;释放消费资源”两个子过程。</p>
<ul>
<li>Try：尝试执行阶段，完成所有业务可执行性的检查（保障一致性），并且预留好全部需用到的业务资源（保障隔离性）。</li>
<li>Confirm：确认执行阶段，不进行任何业务检查，直接使用 Try 阶段准备的资源来完成业务处理。Confirm 阶段可能会重复执行，因此本阶段所执行的操作需要具备幂等性。</li>
<li>Cancel：取消执行阶段，释放 Try 阶段预留的业务资源。Cancel 阶段可能会重复执行，也需要满足幂等性。<br><img src="/media/17351963437904/17352607553723.jpg"><br><img src="/media/17351963437904/17352607737216.jpg"></li>
</ul>
<ol>
<li>最终用户向 Fenix’s Bookstore 发送交易请求：购买一本价值 100 元的《深入理解 Java 虚拟机》。</li>
<li>创建事务，生成事务 ID，记录在活动日志中，进入 Try 阶段：<ul>
<li>用户服务：检查业务可行性，可行的话，将该用户的 100 元设置为“冻结”状态，通知下一步进入 Confirm 阶段；不可行的话，通知下一步进入 Cancel 阶段。</li>
<li>仓库服务：检查业务可行性，可行的话，将该仓库的 1 本《深入理解 Java 虚拟机》设置为“冻结”状态，通知下一步进入 Confirm 阶段；不可行的话，通知下一步进入 Cancel 阶段。</li>
<li>商家服务：检查业务可行性，不需要冻结资源。</li>
</ul>
</li>
<li>如果第 2 步所有业务均反馈业务可行，将活动日志中的状态记录为 Confirm，进入 Confirm 阶段：<ul>
<li>用户服务：完成业务操作（扣减那被冻结的 100 元）。</li>
<li>仓库服务：完成业务操作（标记那 1 本冻结的书为出库状态，扣减相应库存）。</li>
<li>商家服务：完成业务操作（收款 100 元）。</li>
</ul>
</li>
<li>第 3 步如果全部完成，事务宣告正常结束，如果第 3 步中任何一方出现异常，不论是业务异常或者网络异常，都将根据活动日志中的记录，重复执行该服务的 Confirm 操作，即进行最大努力交付。</li>
<li>如果第 2 步有任意一方反馈业务不可行，或任意一方超时，将活动日志的状态记录为 Cancel，进入 Cancel 阶段：<ul>
<li>用户服务：取消业务操作（释放被冻结的 100 元）。</li>
<li>仓库服务：取消业务操作（释放被冻结的 1 本书）。</li>
<li>商家服务：取消业务操作（大哭一场后安慰商家谋生不易）。</li>
</ul>
</li>
<li>第 5 步如果全部完成，事务宣告以失败回滚结束，如果第 5 步中任何一方出现异常，不论是业务异常或者网络异常，都将根据活动日志中的记录，重复执行该服务的 Cancel 操作，即进行最大努力交付。</li>
</ol>
<p>由上述操作过程可见，TCC 其实有点类似 2PC 的准备阶段和提交阶段，但 TCC 是位于用户代码层面，而不是在基础设施层面，这为它的实现带来了较高的灵活性，可以根据需要设计资源锁定的粒度。TCC 在业务执行时只操作预留资源，几乎不会涉及锁和资源的争用，具有很高的性能潜力。但是 TCC 并非纯粹只有好处，它也带来了更高的开发成本和业务侵入性，意味着有更高的开发成本和更换事务实现方案的替换成本，所以，通常我们并不会完全靠裸编码来实现 TCC，而是基于某些分布式事务中间件（譬如阿里开源的Seata）去完成，尽量减轻一些编码工作量。</p>
<p>TCC 事务具有较强的隔离性，避免了“超售”的问题，而且其性能一般来说是本篇提及的几种柔性事务模式中最高的，但它仍不能满足所有的场景。<strong>TCC 的最主要限制是它的业务侵入性很强</strong>，譬如，把我们的场景事例修改如下：由于中国网络支付日益盛行，现在用户和商家在书店系统中可以选择不再开设充值账号，至少不会强求一定要先从银行充值到系统中才能进行消费，允许直接在购物时通过 U 盾或扫码支付，在银行账号中划转货款。这个需求完全符合国内网络支付盛行的现状，却给系统的事务设计增加了额外的限制：如果用户、商家的账号余额由银行管理的话，其操作权限和数据结构就不可能再随心所欲地自行定义，通常也就无法完成冻结款项、解冻、扣减这样的操作，因为银行一般不会配合你的操作。所以 TCC 中的第一步 Try 阶段往往无法施行。</p>
<h2 id="SAGA模式"><a href="#SAGA模式" class="headerlink" title="SAGA模式"></a>SAGA模式</h2><p>SAGA 事务。SAGA 在英文中是“长篇故事、长篇记叙、一长串事件”的意思。</p>
<p>原本 SAGA 的目的是避免大事务长时间锁定数据库的资源，后来才发展成将一个分布式环境中的大事务分解为一系列本地事务的设计模式。SAGA 由两部分操作组成。</p>
<ul>
<li><p>大事务拆分若干个小事务，将整个分布式事务 T 分解为 n 个子事务，命名为 T1，T2，…，Ti，…，Tn。每个子事务都应该是或者能被视为是原子行为。如果分布式事务能够正常提交，其对数据的影响（最终一致性）应与连续按顺序成功提交 Ti等价。</p>
</li>
<li><p>为每一个子事务设计对应的补偿动作，命名为 C1，C2，…，Ci，…，Cn。Ti与 Ci必须满足以下条件：</p>
<ul>
<li>Ti与 Ci都具备幂等性。</li>
<li>Ti与 Ci满足交换律（Commutative），即先执行 Ti还是先执行 Ci，其效果都是一样的。</li>
<li>Ci必须能成功提交，即不考虑 Ci本身提交失败被回滚的情形，如出现就必须持续重试直至成功，或者要人工介入。</li>
</ul>
</li>
<li><p>正向恢复（Forward Recovery）：如果 Ti事务提交失败，则一直对 Ti进行重试，直至成功为止（最大努力交付）。这种恢复方式不需要补偿，适用于事务最终都要成功的场景，譬如在别人的银行账号中扣了款，就一定要给别人发货。正向恢复的执行模式为：T1，T2，…，Ti（失败），Ti（重试）…，Ti+1，…，Tn。</p>
</li>
<li><p>反向恢复（Backward Recovery）：如果 Ti事务提交失败，则一直执行 Ci对 Ti进行补偿，直至成功为止（最大努力交付）。这里要求 Ci必须（在持续重试后）执行成功。反向恢复的执行模式为：T1，T2，…，Ti（失败），Ci（补偿），…，C2，C1。</p>
</li>
</ul>
<p>与 TCC 相比，SAGA 不需要为资源设计冻结状态和撤销冻结的操作，补偿操作往往要比冻结操作容易实现得多。譬如，前面提到的账号余额直接在银行维护的场景，从银行划转货款到 Fenix’s Bookstore 系统中，这步是经由用户支付操作（扫码或 U 盾）来促使银行提供服务；如果后续业务操作失败，尽管我们无法要求银行撤销掉之前的用户转账操作，但是由 Fenix’s Bookstore 系统将货款转回到用户账上作为补偿措施却是完全可行的。</p>
<p>SAGA 必须保证所有子事务都得以提交或者补偿，<strong>但 SAGA 系统本身也有可能会崩溃，所以它必须设计成与数据库类似的日志机制（被称为 SAGA Log）以保证系统恢复后可以追踪到子事务的执行情况</strong>，譬如执行至哪一步或者补偿至哪一步了。另外，尽管补偿操作通常比冻结&#x2F;撤销容易实现，但保证正向、反向恢复过程的能严谨地进行也需要花费不少的工夫，譬如通过服务编排、可靠事件队列等方式完成，所以，SAGA 事务通常也不会直接靠裸编码来实现，一般也是在事务中间件的基础上完成，前面提到的 Seata 就同样支持 SAGA 事务模式。</p>
<h2 id="AT-事务模式"><a href="#AT-事务模式" class="headerlink" title="AT 事务模式"></a>AT 事务模式</h2><p>譬如阿里的 GTS（Global Transaction Service，Seata 由 GTS 开源而来）</p>
<p>从整体上看是 AT 事务是参照了 XA 两段提交协议实现的，但针对 XA 2PC 的缺陷，即在准备阶段必须等待所有数据源都返回成功后，协调者才能统一发出 Commit 命令而导致的木桶效应（所有涉及的锁和资源都需要等待到最慢的事务完成后才能统一释放），设计了针对性的解决方案。</p>
<p><img src="/media/17351963437904/17352016637643.jpg"></p>
<p>大致的做法是在<strong>业务数据提交时自动拦截所有 SQL，将 SQL 对数据修改前、修改后的结果分别保存快照，生成行锁</strong>，通过本地事务一起提交到操作的数据源中，相当于自动记录了重做和回滚日志。如果分布式事务成功提交，那后续清理每个数据源中对应的日志数据即可；如果分布式事务需要回滚，就根据日志数据自动产生用于补偿的“逆向 SQL”。</p>
<p>基于这种补偿方式，分布式事务中所涉及的每一个数据源都可以单独提交，然后立刻释放锁和资源。这种异步提交的模式，<strong>相比起 2PC 极大地提升了系统的吞吐量水平。而代价就是大幅度地牺牲了隔离性，甚至直接影响到了原子性</strong>。因为在缺乏隔离性的前提下，以补偿代替回滚并不一定是总能成功的。</p>
<p>譬如，当本地事务提交之后、分布式事务完成之前，该数据被补偿之前又被其他操作修改过，即出现了脏写（Dirty Write），这时候一旦出现分布式事务需要回滚，就不可能再通过自动的逆向 SQL 来实现补偿，只能由人工介入处理了。</p>
<p>通常来说，脏写是一定要避免的，所有传统关系数据库在最低的隔离级别上都仍然要加锁以避免脏写，因为脏写情况一旦发生，人工其实也很难进行有效处理。<strong>所以 GTS 增加了一个“全局锁”（Global Lock）的机制来实现写隔离，要求本地事务提交之前，一定要先拿到针对修改记录的全局锁后才允许提交，没有获得全局锁之前就必须一直等待，这种设计以牺牲一定性能为代价，避免了有两个分布式事务中包含的本地事务修改了同一个数据，从而避免脏写</strong>。<br><img src="/media/17351963437904/17352018489323.jpg"></p>
<p>在读隔离方面，AT 事务默认的隔离级别是读未提交（Read Uncommitted），这意味着可能产生脏读（Dirty Read）。也可以采用全局锁的方案解决读隔离问题，但直接阻塞读取的话，代价就非常大了，一般不会这样做</p>
</div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/">上一页</a></div><div class="pagination-next"><a href="/page/3/">下一页</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/">1</a></li><li><a class="pagination-link is-current" href="/page/2/">2</a></li><li><a class="pagination-link" href="/page/3/">3</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/7/">7</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="zcct"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">zcct</p><p class="is-size-6 is-block">zcct</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>中国</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives/"><p class="title">64</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories/"><p class="title">4</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags/"><p class="title">12</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://gitee.com/zclvct" target="_blank" rel="me noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="Github" href="https://gitee.com/zclvct"><i class="fab fa-github"></i></a></div></div></div><!--!--><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-09-01T04:00:00.000Z">2024-09-01</time></p><p class="title"><a href="/2024/09/01/redis/GeoHash/">GeoHash</a></p><p class="categories"><a href="/categories/redis/">redis</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-09-01T04:00:00.000Z">2024-09-01</time></p><p class="title"><a href="/2024/09/01/redis/HyperLogLog/">HyperLogLog</a></p><p class="categories"><a href="/categories/redis/">redis</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-09-01T04:00:00.000Z">2024-09-01</time></p><p class="title"><a href="/2024/09/01/redis/Scan%E6%8C%87%E4%BB%A4/">Scan指令</a></p><p class="categories"><a href="/categories/redis/">redis</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-09-01T04:00:00.000Z">2024-09-01</time></p><p class="title"><a href="/2024/09/01/redis/Stream/">Stream</a></p><p class="categories"><a href="/categories/redis/">redis</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-09-01T04:00:00.000Z">2024-09-01</time></p><p class="title"><a href="/2024/09/01/redis/codis%20%E9%9B%86%E7%BE%A4%E6%96%B9%E6%A1%88/">codis 集群方案</a></p><p class="categories"><a href="/categories/redis/">redis</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2024/09/"><span class="level-start"><span class="level-item">九月 2024</span></span><span class="level-end"><span class="level-item tag">63</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/09/"><span class="level-start"><span class="level-item">九月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/java/"><span class="level-start"><span class="level-item">java</span></span><span class="level-end"><span class="level-item tag">30</span></span></a></li><li><a class="level is-mobile" href="/categories/mysql/"><span class="level-start"><span class="level-item">mysql</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/redis/"><span class="level-start"><span class="level-item">redis</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"><span class="level-start"><span class="level-item">分布式</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/juc/"><span class="tag">juc</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/jvm/"><span class="tag">jvm</span><span class="tag">15</span></a></div><div class="control"><a class="tags has-addons" href="/tags/redis/"><span class="tag">redis</span><span class="tag">17</span></a></div><div class="control"><a class="tags has-addons" href="/tags/sql%E4%BC%98%E5%8C%96/"><span class="tag">sql优化</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BA%8B%E5%8A%A1%E5%A4%84%E7%90%86/"><span class="tag">事务处理</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/"><span class="tag">内存模型</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"><span class="tag">垃圾回收</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"><span class="tag">多线程</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9E%B6%E6%9E%84%E5%AE%89%E5%85%A8%E6%80%A7/"><span class="tag">架构安全性</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%B1%BB%E5%8A%A0%E8%BD%BD/"><span class="tag">类加载</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BC%93%E5%AD%98/"><span class="tag">缓存</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%80%8F%E6%98%8E%E5%A4%9A%E7%BA%A7%E5%88%86%E6%B5%81%E7%B3%BB%E7%BB%9F/"><span class="tag">透明多级分流系统</span><span class="tag">6</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="ZCCT" height="28"></a><p class="is-size-7"><span>&copy; 2025 zcct</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">© 2019</p></div><div class="level-end"></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script data-pjax src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script data-pjax src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js"></script><script src="/js/pjax.js"></script><!--!--><!--!--><!--!--><script data-pjax src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script data-pjax src="/js/insight.js" defer></script><script data-pjax>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>